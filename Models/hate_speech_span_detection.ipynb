{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b51917f8",
   "metadata": {},
   "source": [
    "\n",
    "# Hate Speech Span Detection and Categorization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a047b462",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Configuration ---\n",
    "# Fill these paths and hyperparameters before running.\n",
    "CONFIG = {\n",
    "    # Task: choose one of [\"categorization\", \"detection\"]\n",
    "    \"task\": \"categorization\",\n",
    "\n",
    "    # Data: CSVs with columns: Tweet_id, tokens(list), tags(list)\n",
    "    \"train_set\": \"train.csv\",\n",
    "    \"test_set\": \"test.csv\",\n",
    "    \"non_hateful\": \"non_hateful.csv\",\n",
    "\n",
    "    # Model & Training\n",
    "    \"model_name\": \"dbmdz/bert-base-turkish-cased\",\n",
    "    \"learning_rate\": 5e-5,\n",
    "    \"batch_size\": 4,\n",
    "    \"epochs\": 10,\n",
    "    \"warmup_ratio\": 0.1,\n",
    "    \"early_stop_patience\": 3,\n",
    "    \"weight_decay\": 0.0,\n",
    "    \"eval_train_split_ratio\": 0.1,  # fraction of train used as eval\n",
    "    \"test_sample_size\": 300,         # held-out sample from test_set (0 = use full test file)\n",
    "    \"random_state\": 42,\n",
    "    \"log_steps\": 100,\n",
    "\n",
    "    # Output dir (Trainer output)\n",
    "    \"output_dir\": \"train\"\n",
    "}\n",
    "print(\"Loaded CONFIG. Edit paths and hyperparameters above as needed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df35df98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Imports ---\n",
    "import os\n",
    "from ast import literal_eval\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "import evaluate\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForTokenClassification,\n",
    "    AutoModelForTokenClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    EarlyStoppingCallback,\n",
    ")\n",
    "\n",
    "# --- Label Maps ---\n",
    "CATEGORIZATION_ID2LABEL = {\n",
    "    0: \"O\",\n",
    "    1: \"I-Exclusive/Discriminatory Discourse\",\n",
    "    2: \"I-Exaggeration; Generalization; Attribution; Distortion\",\n",
    "    3: \"I-Threat of Enmity; War; Attack; Murder; or Harm\",\n",
    "    4: \"I-Symbolization\",\n",
    "    5: \"I-Swearing; Insult; Defamation; Dehumanization\",\n",
    "}\n",
    "CATEGORIZATION_LABEL2ID = {v: k for k, v in CATEGORIZATION_ID2LABEL.items()}\n",
    "\n",
    "DETECTION_ID2LABEL = {\n",
    "    0: \"O\",\n",
    "    1: \"B-HATE\",\n",
    "    2: \"I-HATE\",\n",
    "}\n",
    "DETECTION_LABEL2ID = {v: k for k, v in DETECTION_ID2LABEL.items()}\n",
    "print(\"Imports complete and label maps ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ec6c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Helper Functions ---\n",
    "def load_dataframes(\n",
    "    train_set_path: str,\n",
    "    test_set_path: str,\n",
    "    non_hateful_path: str,\n",
    "    test_sample_size: int,\n",
    "    random_state: int = 42,\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Returns (df_train_set_merged_with_non_hateful, df_test).\"\"\"\n",
    "    df_train_set = pd.read_csv(train_set_path)\n",
    "    df_test_set = pd.read_csv(test_set_path)\n",
    "    df_not_spans = pd.read_csv(non_hateful_path)\n",
    "\n",
    "    for df in (df_test_set, df_train_set, df_not_spans):\n",
    "        df[\"tokens\"] = df[\"tokens\"].apply(literal_eval)\n",
    "        df[\"tags\"] = df[\"tags\"].apply(literal_eval)\n",
    "        df[\"Tweet_id\"] = df[\"Tweet_id\"]\n",
    "\n",
    "    df_train_set_merged_with_non_hateful = pd.concat([df_train_set, df_not_spans], ignore_index=True)\n",
    "\n",
    "    if test_sample_size > 0:\n",
    "        df_test = df_test_set.sample(test_sample_size, random_state=random_state)\n",
    "    else:\n",
    "        df_test = df_test_set.copy()\n",
    "\n",
    "    exclude_ids = set(df_test[\"Tweet_id\"].tolist())\n",
    "    df_train_set_merged_with_non_hateful = df_train_set_merged_with_non_hateful[\n",
    "        ~df_train_set_merged_with_non_hateful[\"Tweet_id\"].isin(exclude_ids)\n",
    "    ]\n",
    "\n",
    "    return df_train_set_merged_with_non_hateful, df_test\n",
    "\n",
    "\n",
    "def make_hf_datasets(df_train_set_merged_with_non_hateful: pd.DataFrame, df_test: pd.DataFrame) -> DatasetDict:\n",
    "    train_dataset = Dataset.from_pandas(df_train_set_merged_with_non_hateful)\n",
    "    test_dataset = Dataset.from_pandas(df_test)\n",
    "    ds = DatasetDict({\"train\": train_dataset, \"test\": test_dataset})\n",
    "    return ds\n",
    "\n",
    "\n",
    "def build_tokenizer(model_name: str):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, add_prefix_space=True)\n",
    "    return tokenizer\n",
    "\n",
    "\n",
    "def align_labels_with_tokens(examples, tokenizer, label_list: List[str]):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            else:\n",
    "                label_ids.append(label[word_idx])\n",
    "        labels.append(label_ids)\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "\n",
    "def build_metrics(id2label: Dict[int, str]):\n",
    "    seqeval = evaluate.load(\"seqeval\")\n",
    "    label_list = list(id2label.values())\n",
    "\n",
    "    def compute_metrics(p):\n",
    "        predictions, labels = p\n",
    "        predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "        true_predictions = [\n",
    "            [label_list[p_i] for (p_i, l_i) in zip(prediction, label) if l_i != -100]\n",
    "            for prediction, label in zip(predictions, labels)\n",
    "        ]\n",
    "        true_labels = [\n",
    "            [label_list[l_i] for (p_i, l_i) in zip(prediction, label) if l_i != -100]\n",
    "            for prediction, label in zip(predictions, labels)\n",
    "        ]\n",
    "\n",
    "        results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "        return {\n",
    "            \"precision\": results.get(\"overall_precision\", 0.0),\n",
    "            \"recall\": results.get(\"overall_recall\", 0.0),\n",
    "            \"f1\": results.get(\"overall_f1\", 0.0),\n",
    "            \"accuracy\": results.get(\"overall_accuracy\", 0.0),\n",
    "        }\n",
    "\n",
    "    return compute_metrics\n",
    "\n",
    "\n",
    "def build_trainer(\n",
    "    tokenized_dataset: DatasetDict,\n",
    "    model_name: str,\n",
    "    id2label: Dict[int, str],\n",
    "    label2id: Dict[str, int],\n",
    "    learning_rate: float,\n",
    "    batch_size: int,\n",
    "    num_epochs: int,\n",
    "    warmup_ratio: float,\n",
    "    weight_decay: float,\n",
    "    early_stop_patience: int,\n",
    "    logging_steps: int = 100,\n",
    "    eval_train_split_ratio: float = 0.1,\n",
    "    seed: int = 42,\n",
    "):\n",
    "    num_labels = len(id2label)\n",
    "\n",
    "    model = AutoModelForTokenClassification.from_pretrained(\n",
    "        model_name, num_labels=num_labels, id2label=id2label, label2id=label2id\n",
    "    )\n",
    "    tokenizer = build_tokenizer(model_name)\n",
    "    data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "    compute_metrics = build_metrics(id2label)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=CONFIG[\"output_dir\"],\n",
    "        learning_rate=learning_rate,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        metric_for_best_model=\"eval_f1\",\n",
    "        load_best_model_at_end=True,\n",
    "        greater_is_better=True,\n",
    "        num_train_epochs=num_epochs,\n",
    "        evaluation_strategy=\"epoch\",   # FIX: correct HF arg (instead of eval_strategy)\n",
    "        save_strategy=\"epoch\",\n",
    "        logging_dir=os.path.join(CONFIG[\"output_dir\"], \"logs\"),\n",
    "        logging_steps=logging_steps,\n",
    "        save_total_limit=1,\n",
    "        push_to_hub=False,\n",
    "        warmup_ratio=warmup_ratio,\n",
    "        weight_decay=weight_decay,\n",
    "    )\n",
    "\n",
    "    split_ds = tokenized_dataset[\"train\"].train_test_split(test_size=eval_train_split_ratio, seed=seed)\n",
    "    train_dataset = split_ds[\"train\"]\n",
    "    eval_dataset = split_ds[\"test\"]\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=early_stop_patience)],\n",
    "    )\n",
    "\n",
    "    return trainer, tokenizer\n",
    "print(\"Helper functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36afdf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Build Datasets ---\n",
    "task = CONFIG[\"task\"]\n",
    "if task == \"categorization\":\n",
    "    id2label = CATEGORIZATION_ID2LABEL\n",
    "    label2id = CATEGORIZATION_LABEL2ID\n",
    "else:\n",
    "    id2label = DETECTION_ID2LABEL\n",
    "    label2id = DETECTION_LABEL2ID\n",
    "\n",
    "df_train_set_merged_with_non_hateful, df_test = load_dataframes(\n",
    "    CONFIG[\"train_set\"],\n",
    "    CONFIG[\"test_set\"],\n",
    "    CONFIG[\"non_hateful\"],\n",
    "    CONFIG[\"test_sample_size\"],\n",
    "    CONFIG[\"random_state\"],\n",
    ")\n",
    "ds = make_hf_datasets(df_train_set_merged_with_non_hateful, df_test)\n",
    "\n",
    "tokenizer = build_tokenizer(CONFIG[\"model_name\"])\n",
    "\n",
    "def _map_fn(examples):\n",
    "    return align_labels_with_tokens(examples, tokenizer, list(id2label.values()))\n",
    "\n",
    "tokenized_dataset = ds.map(_map_fn, batched=True)\n",
    "print(tokenized_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd719423",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Train ---\n",
    "trainer, tokenizer = build_trainer(\n",
    "    tokenized_dataset=tokenized_dataset,\n",
    "    model_name=CONFIG[\"model_name\"],\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    learning_rate=CONFIG[\"learning_rate\"],\n",
    "    batch_size=CONFIG[\"batch_size\"],\n",
    "    num_epochs=CONFIG[\"epochs\"],\n",
    "    warmup_ratio=CONFIG[\"warmup_ratio\"],\n",
    "    weight_decay=CONFIG[\"weight_decay\"],\n",
    "    early_stop_patience=CONFIG[\"early_stop_patience\"],\n",
    "    logging_steps=CONFIG[\"log_steps\"],\n",
    "    eval_train_split_ratio=CONFIG[\"eval_train_split_ratio\"],\n",
    "    seed=CONFIG[\"random_state\"]\n",
    ")\n",
    "\n",
    "# Uncomment to run training:\n",
    "# trainer.train()\n",
    "print(\"Trainer is ready. Uncomment trainer.train() to start training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc1d0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Evaluate on held-out test set ---\n",
    "# Uncomment after training:\n",
    "# metrics = trainer.evaluate(tokenized_dataset[\"test\"])\n",
    "# print(f\"[{task.upper()}] Test metrics:\", metrics)\n",
    "\n",
    "# predictions, label_ids, metrics = trainer.predict(tokenized_dataset[\"test\"])\n",
    "# print(f\"[{task.upper()}] Test metrics from predict:\", metrics)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
